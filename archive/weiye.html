<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge，chrome=1">
    <title>Wei Ye, Peking University - 叶蔚，北京大学</title>
    <link href="https://se.pku.edu.cn/docs/2020-09/20200915182220784581.ico" rel="icon" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="/docs/2020-06/20200601131620322522.css" />
</head>

<body>
    <div class="header">
        <div class="header-container">
            <div class="title">
                <img class="badge" src="/images/content/2020-05/20200507012922154227.png" />
                <div>
                    <div class="text">
                        <a href="https://se.pku.edu.cn/kcl">The Knowledge Computing Lab</a>
                    </div>
                    <div class="subtext">
                        <a href="https://se.pku.edu.cn/kcl">The National Engineering Research Center for Software Engineering</a>
                    </div>
                </div>
            </div>
        </div>
        <div class="title-mobile">
            <div class="title">
                <img class="badge" src="/images/content/2020-05/20200507012922154227.png" />
                <div class="text no-top">
                    <div class="main">北大知识计算实验室</div>
                    <div class="sub">The Knowledge Computing Lab</div>
                </div>
                <div class="text top">
                    <div class="main">The Knowledge Computing Lab</div>
                    <div class="sub">At The National Engineering Research Center for Software Engineering</div>
                </div>
            </div>
        </div>
    </div>
    <div class="container">
        <div class="background">
            <div class="background-round" style="width: 785px; height: 785px; right: -100px; top: -330px;"></div>
            <div class="background-round" style="width: 315px; height: 315px; left: -180px; top: 660px;"></div>
            <div class="background-round" style="width: 607px; height: 607px; right: -360px; top: 1120px;"></div><!-- 
            <div class="background-round" style="width: 715px; height: 715px; left: -180px; top: 1520px;"></div>
            <div class="background-round" style="width: 375px; height: 375px; right: -110px; top: 2600px;"></div> -->
            <!-- <div class="background-round" style="width: 607px; height: 607px; left: -260px; top: 3290px;"></div> -->
            <!-- <div class="background-round" style="width: 845px; height: 845px; right: -320px; top: 4840px;"></div> -->
            <!-- <div class="background-round" style="width: 427px; height: 427px; left: -260px; top: 6390px;"></div> -->
        </div>
        <a class="target-fix" id="introduction" name="introduction"></a>
        <div class="people">
            <div class="group" style="margin-top: 40px;">
                <div class="professor" style="height: 250px;">
                    <div class="avatar" style="height: 250px; width: 250px; background-color: initial;">
                        <img style="min-height:  250px; min-width:  250px; border-radius: 125px;" src="/images/content/2020-05/20200507012922152906.jpg" />
                    </div>
                    <div class="info">
                        <div class="name">Wei Ye</div>
                        <div class="title">Associate Researcher, Director of Knowledge Computing Lab</div>
                        <div class="title">National Engineering Research Center for Software Engineering, Peking University</div>
                        <div class="title" style="font-size: 15px"><a href="mailto:wye@pku.edu.cn">wye#pku.edu.cn</a></div>
                        <div class="tags">
                            <div class="tag">Natural Language Processing</div>
                            <div class="tag">Artificial Intelligence</div>
                            <div class="tag">Software Engineering</div>
                            <div class="tag">Software Security</div>
                        </div>
                    </div>
            </div>
        </div>
        <div class="introduction"  style="margin-top: initial; height: initial;">
            <h1>Introduction</h1>
            <!-- <div class="photo">
                <img src="/images/content/2020-05/20200507185349480209.jpg" />
            </div>
            <div class="aphorism">Welcome to the Knowledge Computing Group (KCG) of Peking University, a center of excellence for knowledge computing research and practice established in 2017.
            </div> -->
            <div class="text" style="width: initial; height: initial; position: relative; top: initial;">
                <p>Dr. Wei Ye is now an associate professor at National Engineering Research Center for Software Engineering, Peking University. In 2011, he obtained a doctorate degree from the School of Electronics Engineering and Computer Science, Peking University, working with Prof. Shikun Zhang. Wei Ye has a broad interest in real-world problems related to natural languages, knowledge graphs, and programming languages, and large language models (LLMs). Specifically, he is currently delving into the pre-training, alignment, and evaluation of LLMs, including ChatGPT-like LLMs, code LLMs and multi-modal LLMs.</p>
                <p><span style="font-weight:bold"><a href="https://se.pku.edu.cn/kcl">The Knowledge Computing Lab</a></span> at Peking University is part of National Engineering and Research Center for Software Engineering, where faculties, students and software engineers work together on advanced algorithms towards natural language understanding and programming language comprehension. Our research topics include, but are not limited to, relation extraction, sequence modeling, sentiment analysis, code knowledge graph, code summarization and code retrieval. We have won more than 10 awards in national and international AI competitions. We distinguish ourselves as being practice-oriented, as our researches have been applied in large-scale real-world projects in areas such as enterprise intelligence, medical AI, petition, legal system, and human resources.</p>
            </div>
        </div>
        <div class="introduction" style="margin:  20px 0; height: initial;">
            <div class="wanted" style="position: relative; right: initial; top: initial; width: initial; height: initial;">
                <div class="wanted-container" style="height: initial;">
                    <img class="wanted-icon" src="/images/content/2020-05/20200507185349480195.png" style="top: 10px" />
                    <p>We are looking for highly self-motivated students to work with us as PhD candidates (several positions open for 2026 Fall) or for Master's Degree. If you share our vision and are interested in working with us, please send your resume to <a>wye#pku.edu.cn</a>.
                    </p>
                </div>
            </div>
        </div>

        <a class="target-fix" id="papers" name="papers"></a>
        <div class="papers">
            <h1 style="width: initial;">Recent Papers</h1>
            <div class="table-container">
                <div id="papers-container">
                    <table>
                        <thead>
                            <tr>
                                <th>No.</th>
                                <th>Title</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr><td>01</td><td>Muzhi Yu, Zhengran Zeng, Wei Ye*, Jinan Sun*, Xiaolong Bai, Shikun Zhang. R3-Bench: Reproducible Real-world Reverse Engineering Dataset for Symbol Recovery. ASE'25 (CCF Rank A, Full Paper)</td></tr>
<tr><td>02</td><td>Yutao Mou, Xiao Deng, Yuxiao Luo, Shikun Zhang, Wei Ye*. Can You Really Trust Code Copilot? Evaluating Large Language Models from a Code Security Perspective. ACL'25 (CCF Rank A, Full Paper)</td></tr>
<tr><td>03</td><td>Bo Li, Gexiang Fang, Wei Ye*, Zhenghua Xu*, Jinglei Zhang, Hao Cheng, Shikun Zhang. MPL: Multiple Programming Languages with Large Language Models for Information Extraction. ACL'25 (Findings)</td></tr>
<tr><td>04</td><td>Zhuohao Yu, Weizheng Gu, Yidong Wang, Xingru Jiang, Zhengran Zeng, Jindong Wang, Wei Ye*, Shikun Zhang. Reasoning Through Execution: Unifying Process and Outcome Rewards for Code Generation. ICML'25 (CCF Rank A, Full Paper)</td></tr>
<tr><td>05</td><td>Xiaoling Zhou, Ye Wei*, Zhemg Lee, Shikun Zhang*. Robustness to Spurious Correlations via Dynamic Knowledge Transfer. IJCAI'25 (CCF Rank A, Full Paper)</td></tr>
<tr><td>06</td><td>Peiyang Liu, Xi Wang, Ziqiang Cui, Wei Ye*. Queries Are Not Alone: Clustering Text Embeddings for Video Search. SIGIR'25 (CCF Rank A, Full Paper)</td></tr>
<tr><td>07</td><td>Xiaoling Zhou, Wei Ye*, Zhemg Lee, Lei Zou, Shikun Zhang*. Valuing Training Data via Causal Inference for In-Context Learning. TKDE'25 (CCF Rank A, Journal)</td></tr>
<tr><td>08</td><td>Hongrui Jia, Chaoya Jiang, Haiyang Xu, Wei Ye*, Mengfan Dong, Ming Yan, Ji Zhang, Fei Huang, Shikun Zhang. SymDPO: Boosting In-Context Learning of Large Multimodal Models with Symbol Demonstration Direct Preference Optimization. CVPR'25 (CCF Rank A, Full Paper)</td></tr>
<tr><td>09</td><td>Xiaoling Zhou, Zhemg Lee, Wei Ye*, Rui Xie, Wenbo Zhang, Guanju Peng, Zongze Li, Shikun Zhang*. All-Optical Nonlinear Diffractive Deep Network for Ultrafast Image Denoising. CVPR'25 (CCF Rank A, Full Paper)</td></tr>
<tr><td>10</td><td>Xiaoling Zhou, Mingjie Zhang, Zhemg Lee, Wei Ye*, Shikun Zhang*. HaDeMiF: Hallucination Detection and Mitigation in Large Language Models. ICLR'25</td></tr>
<tr><td>11</td><td>Zile Qiao, Wei Ye*, Yong Jiang, Tong Mo, Pengjun Xie, Weiping Li, Fei Huang, Shikun Zhang. Supportiveness-based Knowledge Rewriting for Retrieval-augmented Language Modeling. NAACL'25 (Findings)</td></tr>
<tr><td>12</td><td>Yutao Mou, Shikun Zhang, Wei Ye*. SG-Bench: Evaluating LLM Safety Generalization Across Diverse Tasks and Prompt Types. NeurIPS'24 (CCF Rank A,  Datasets and Benchmarks Track)</td></tr>
<tr><td>13</td><td>Chaoya Jiang, Jia Hongrui, Haiyang Xu, Wei Ye*, Mengfan Dong, Ming Yan, Ji Zhang, Fei Huang, Shikun Zhang. MaVEn: An Effective Multi-granularity Hybrid Visual Encoding Framework for Multimodal Large Language Model. NeurIPS'24 (CCF Rank A, Full Paper)</td></tr>
<tr><td>14</td><td>Yidong Wang, Qi Guo, Wenjin Yao, Hongbo Zhang, Xin Zhang, Zhen Wu, Meishan Zhang, Xinyu Dai, Min zhang, Qingsong Wen, Wei Ye*, Shikun Zhang*, Yue Zhang*. AutoSurvey: Large Language Models Can Automatically Write Surveys. NeurIPS'24 (CCF Rank  A, Full Paper)</td></tr>
<tr><td>15</td><td>Wenjin Yao, Yidong Wang, Zhuohao Yu, Rui Xie, Shikun Zhang, Wei Ye*. PURE: Aligning LLM via Pluggable Query Reformulation for Enhanced Helpfulness. EMNLP'24 (Findings)</td></tr>
<tr><td>16</td><td>Zhuohao Yu, Chang Gao, Wenjin Yao, Yidong Wang, Zhengran Zeng, Wei Ye*, Jindong Wang, Yue Zhang, Shikun Zhang. FreeEval: A Modular Framework for Trustworthy and Efficient Evaluation of Large Language Models. EMNLP’24 (System Demonstration Track)</td></tr>
<tr><td>17</td><td>Xuanwang Zhang, Yun-Ze Song, Yidong Wang, Shuyun Tang, Xinfeng Li, Zhengran Zeng, Zhen Wu, Wei Ye, Wenyuan Xu, Yue Zhang, Xinyu Dai, Shikun Zhang, Qingsong Wen. RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation. EMNLP’24 (System Demonstration Track)</td></tr>
<tr><td>18</td><td>Chaoya Jiang, Wei Ye*, Mengfan Dong, Jia Hongrui, Haiyang Xu, Ming Yan, Ji Zhang, Shikun Zhang. Hal-Eval: A Universal and Fine-grained Hallucination Evaluation Framework for Large Vision Language Models. MM'24 (CCF Rank A, Full Paper)</td></tr>
<tr><td>19</td><td>Xiao Deng, Fuyao Duan, Rui Xie, Wei Ye* and Shikun Zhang. Improving long-tail vulnerability detection through data augmentation based on large language models. ICSME'24 (CCF Rank B, Full Paper)</td></tr>
<tr><td>20</td><td>Xiaoling Zhou, Wei Ye*, Yidong Wang, Chaoya Jiang, Zhemg Lee, Rui Xie, Shikun Zhang*. Enhancing In-Context Learning via Implicit Demonstration Augmentation. ACL’24 (CCF Rank A, Full Paper)</td></tr>
<tr><td>21</td><td>Zhuohao Yu, Chang Gao, Wenjin Yao, Yidong Wang, Wei Ye*, Jindong Wang, Xing Xie, Yue Zhang, Shikun Zhang. KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models. ACL’24 (CCF Rank A, Full Paper)</td></tr>
<tr><td>22</td><td>Dingyao Yu, Yang An, Wei Ye*, Xiongfeng Xiao, Shaoguang Mao, Tao Ge, Shikun Zhang. Refining Corpora from a Model Calibration Perspective for Chinese Spelling Correction. ACL’24 (Findings)</td></tr>
<tr><td>23</td><td>Qi Guo, Leiyu Wang, Yidong Wang, Wei Ye*, Shikun Zhang*. What Makes a Good Order of Examples in In-Context Learning. ACL’24 (Findings)</td></tr>
<tr><td>24</td><td>Zeqian Ju, Yuancheng Wang, Kai Shen, Xu Tan, Detai Xin, Dongchao Yang, Yanqing Liu, Yichong Leng, Kaitao Song, Siliang Tang, Zhizheng Wu, Tao Qin, Xiang-Yang Li, Wei Ye, Shikun Zhang, Jiang Bian, Lei He, Jinyu Li, Sheng Zhao. NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models. ICML'24 (CCF Rank A, Full Paper)</td></tr>
<tr><td>25</td><td>Xiaoling Zhou, Wei Ye*, Zhemg Lee, Rui Xie, Shikun Zhang. Boosting Model Resilience via Implicit Adversarial Data Augmentation. IJCAI'24 (CCF Rank A, Full Paper)</td></tr>
<tr><td>26</td><td>Zhengran Zeng, Yidong Wang, Rui Xie, Wei Ye*, Shikun Zhang*.CoderUJB: An Executable and Unified Java Benchmark for Practical Programming Scenarios. ISSTA'24 (CCF Rank A, Full Paper)</td></tr>
<tr><td>27</td><td>Chaoya Jiang, Haiyang Xu, Mengfan Dong, Jiaxing Chen, Wei Ye*, Ming Yan, Qinghao Ye, Ji Zhang, Fei Huang, Shikun Zhang. Hallucination Augmented Contrastive Learning for Multimodal Large Language Model. CVPR'24 (CCF Rank A, Full Paper)</td></tr>
<tr><td>28</td><td>Yidong Wang, Zhuohao Yu, Zhengran Zeng, Linyi Yang, Wenjin Yao, Cunxiang Wang, Hao Chen, Chaoya Jiang, Rui Xie, Jindong Wang, Xing Xie, Wei Ye*, Shikun Zhang, Yue Zhang. PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization. ICLR'24</td></tr>
<tr><td>29</td><td>Linyi Yang, Shuibai Zhang, Zhuohao Yu, Guangsheng Bao, Yidong Wang, Jindong Wang, Ruochen Xu, Wei Ye, Xing Xie, Weizhu Chen, Yue Zhang. Supervised Knowledge Makes Large Language Models Better In-context Learners. ICLR'24</td></tr>
<tr><td>30</td><td>Chaoya Jiang，Wei Ye*，Haiyang Xu，Qinghao Ye，Ming Yan，Ji Zhang，Shikun Zhang. TiMix: Text-aware Image Mixing for Effective Vision-Language Pretraining. AAAI'24 (CCF Rank A, Full Paper)</td></tr>
<tr><td>31</td><td>Bo Li, Wei Ye*, Quansen Wang, Wen Zhao, Shikun Zhang. Labels Need Prompts Too: Mask Matching for Natural Language Understanding Tasks. AAAI'24 (CCF Rank A, Full Paper)</td></tr>
<tr><td>32</td><td>Dingyao Yu, Kaitao Song, Peiling Lu, Tianyu He, Xu Tan, Wei Ye*, Shikun Zhang*, Jiang Bian. MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models. EMNLP'23 (System Demonstrations)</td></tr>
<tr><td>33</td><td>Chaoya Jiang, Haiyang Xu, Wei Ye*, Qinghao Ye, Chenliang Li, Ming Yan, Bin Bi, Shikun Zhang, Fei Huang, Ji Zhang. COPA: Efficient Vision-Language Pre-training through Collaborative Object- and Patch-Text Alignment. MM'23 (CCF Rank A, Full Paper) </td></tr>
<tr><td>34</td><td>Chaoya Jiang, Haiyang Xu, Wei Ye*, Qinghao Ye, Chenliang Li, Ming Yan, Bin Bi, Shikun Zhang, Fei Huang, Songfang Huang. BUS:Efficient and Effective Vision-language Pretraining with Bottom-Up Patch Summarization. ICCV'23 (CCF Rank A, Full Paper)</td></tr>
<tr><td>35</td><td>Yidong Wang, Zhuohao Yu, Jindong Wang*, Qiang Heng, Hao Chen, Wei Ye*, Rui Xie, Xing Xie, Shikun Zhang*. Exploring Vision-Language Models for Imbalanced Learning. IJCV (CCF Rank A Journal)</td></tr>
<tr><td>36</td><td>Chaoya Jiang, Wei Ye*, Haiyang Xu, Shikun Zhang, Songfang Huang and Fei Huang. Vision Lanauge Pre-training by Contrastive Learning with Cross-Modal Similarity Regulation. ACL’23 (CCF Rank A, Full Paper)</td></tr>
<tr><td>37</td><td>Zile Qiao, Wei Ye, Dingyao Yu, Tong Mo, Weiping Li and Shikun Zhang. Improving Knowledge Graph Completion with Generative Hard Negative Mining. ACL’23 (Findings)</td></tr>
<tr><td>38</td><td>Chaoya Jiang, Rui Xie, Wei Ye*, Jinan Sun and Shikun Zhang. Exploiting Pseudo Image Captions for Multimodal Summarization. ACL’23 (Findings)</td></tr>
<tr><td>39</td><td>Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen, Runkai Zheng, Yidong Wang, Linyi Yang, Wei Ye, Haojun Huang, Xiubo Geng, Binxing Jiao, Yue Zhang, Xing Xie. On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective. ICLR'23 (Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models)</td></tr>
<tr><td>40</td><td>Bo Li, Dingyao Yu, Wei Ye*, Jinglei Zhang, Shikun Zhang*. Sequence Generation with Label Augmentation for Relation Extraction. AAAI'23 (CCF Rank A, Full Paper)</td></tr>
<tr><td>41</td><td>Bo Li, Wei Ye*, Jinglei Zhang, Shikun Zhang*. Reviewing Labels: Label Graph Network with Top-k Prediction Set for Relation Extraction. AAAI'23 (CCF Rank A, Full Paper)</td></tr>
<tr><td>42</td><td>Xi Xiangyu, Jianwei Lv, Shuaipeng Liu, Wei Ye*, Fan Yang and Guanglu Wan. MUSIED: A Benchmark for Event Detection from Multi-Source Heterogeneous Informal Texts. EMNLP'22 (CCF Rank B, Full Paper)</td></tr>
<tr><td>43</td><td>Chaoya Jiang, Haiyang Xu, Chenliang Li, Ming Yan, Wei Ye*, Shikun Zhang*, Bin Bi and Songfang Huang. TRIPS:Efficient Vision-and-Language Pre-training with Text-relevant Patch Selection. EMNLP'22 (CCF Rank B, Full Paper)</td></tr>
<tr><td>44</td><td>Yidong Wang, Hao Chen, Yue Fan, Wang SUN, Ran Tao, Wenxin Hou, Renjie Wang, Linyi Yang, Zhi Zhou, Lan-Zhe Guo, Heli Qi, Zhen Wu, Yu-Feng Li, Satoshi Nakamura, Wei Ye, Marios Savvides, Bhiksha Raj, Takahiro Shinozaki, Bernt Schiele, Jindong Wang, Xing Xie, Yue Zhang. USB: A Unified Semi-supervised Learning Benchmark, NeurIPS'22 (CCF Rank A, Datasets and Benchmarks Track)</td></tr>
<tr><td>45</td><td>Botao Yu, Peiling Lu, Rui Wang, Wei Hu, Xu Tan, Wei Ye, Shikun Zhang, Tao Qin, Tie-Yan Liu. Museformer: Transformer with Fine- and Coarse-Grained Attention for Music Generation. NeurIPS'22 (CCF Rank A, Full Paper)</td></tr>
<tr><td>46</td><td>Peiyang Liu, Xi Xiangyu, Wei Ye* and Shikun Zhang. Label Smoothing for Text Mining, COLING'22 (CCF Rank B, Full Paper)</td></tr>
<tr><td>47</td><td>Zile Qiao, Wei Ye*, Tong Zhang, Tong Mo, Weiping Li and Shikun Zhang. Exploiting Hybrid Semantics of Relation Paths for Multi-hop Question Answering Over Knowledge Graphs, COLING'22 (CCF Rank B, Full Paper)</td></tr>
<tr><td>48</td><td>Yinyi Wei, Shuaipeng Liu, Jianwei Lv, Xi Xiangyu, Wei Ye*, Tong Mo, Fan Yang and Guanglu Wan. DESED: Dialogue-based Explanation for Sentence-level Event Detection, COLING'22 (CCF Rank B, Full Paper)</td></tr>
<tr><td>49</td><td>Rui Xie, Tianxiang Hu, Wei Ye*, Shikun Zhang*. Low-Resources Project-Specific Code Summarization, ASE'22 (CCF Rank A, Full Paper)</td></tr>
<tr><td>50</td><td>Xiangyu Xi, Chenxu Lv, Yuncheng Hua, Wei Ye*, Chaobo Sun, Shuaipeng Liu, Fan Yang, Guanglu Wan. A Low-Cost, Controllable and Interpretable Task-Oriented Chatbot: With Real-World After-Sale Services as Example. SIGIR'22 (Industry Track)</td></tr>
<tr><td>51</td><td>Zheyu Ying, Xueyang Liu*, Jinglei Zhang, Rui Xie, Guochang Wen, Xiongfeng Xiao, Shikun Zhang. 3Rs:Data Augmentation Techniques Using Document Contexts For Low-Resource Chinese Named Entity Recognition. IJCNN'22(CCF Rank C,full paper) </td></tr>
<tr><td>52</td><td>Tong Zhang, Wei Ye*, Baosong Yang, Long Zhang, Xingzhang Ren, Dayiheng Liu, Jinan Sun*, Shikun Zhang, Haibo Zhang, Wen Zhao. Frequency-Aware Contrastive Learning for Neural Machine Translation. AAAI'22 (CCF Rank A, Full Paper)</td></tr>
<tr><td>53</td><td>Peiyang Liu, Xi Wang, Sen Wang, Wei Ye*, Xiangyu Xi and Shikun Zhang. Improving Embedding-based Large-scale Retrieval via Label Enhancement. In EMNLP'21 (Findings) </td></tr>
<tr><td>54</td><td>Peiyang Liu, Xi Wang, Lin Wang, Wei Ye*, Xiangyu Xi and Shikun Zhang. Distilling Knowledge from BERT into Simple Fully Connected Neural Networks for Efficient Vertical Retrieval. In CIKM'21 (CCF Rank B, Applied Paper) </td></tr>
<tr><td>55</td><td>Xi Xiangyu, Wei Ye*, Shikun Zhang*, Quanxiu Wang, Huixing Jiang and Wei Wu. Capturing Event Argument Interaction via A Bi-Directional Entity-Level Recurrent Decoder. In ACL'21 (CCF Rank A, Full Paper)</td></tr>
<tr><td>56</td><td>Tong Zhang, Long Zhang, Wei Ye*, Bo Li, Jinan Sun, Shikun Zhang*, Xiaoyu Zhu and Wen Zhao. Point, Disambiguate and Copy: Incorporating Bilingual Dictionaries for Neural Machine Translation. In ACL'21 (CCF Rank A, Full Paper)</td></tr>
<tr><td>57</td><td>Luyao Ma, Yating Zhang, Tianyi Wang, Xiaozhong Liu, Wei Ye*, Changlong Sun and Shikun Zhang. Legal Judgment Prediction with Multi-Stage Case Representation Learning in the Real Court Setting. In SIGIR'21. (CCF Rank A, Full Paper)</td></tr>
<tr><td>58</td><td>Long Zhang, Tong Zhang, Haibo Zhang, Baosong Yang, Wei Ye* and Shikun Zhang. Multi-Hop Transformer for Document-Level Machine Translation. In NAACL'21. (CCF Rank C, Full Paper)</td></tr>
<tr><td>59</td><td>Peiyang Liu, Sen Wang, Xi Wang, Wei Ye*, Shikun Zhang, QuadrupletBERT: An Efﬁcient Model For Embedding-Based Large-Scale Retrieval. In NAACL'21.  (CCF Rank C, Short Paper)</td></tr>
<tr><td>60</td><td>Rui Xie, Wei Ye*, Jinan Sun, Shikun Zhang. Exploiting Method Names to Improve Code Summarization: A Deliberation Multi-Task Learning Approach, ICPC'21 (CCF Rank B, Full Paper)</td></tr>
<tr><td>61</td><td>Xiangyu Xi, Wei Ye*, Tong Zhang, Quanxiu Wang, Shikun Zhang, Huixing Jiang, Wei Wu. Improve Event Detection by Exploiting Label Hierarchy. In ICASSP'21 (CCF Rank B, Full Paper)</td></tr>
<tr><td>62</td><td>Tianxiang Hu, Jingxi Liang, Wei Ye*, Shikun Zhang. Keyword-Aware Encoder for Abstractive Text Summarization. In DASFAA’21 (CCF Rank B, Full Paper)</td></tr>
<tr><td>63</td><td>Bo Li, Wei Ye*, Canming Huang and Shikun Zhang. Multi-view Inference for Relation Extraction with Uncertain Knowledge. In AAAI'21 (CCF Rank A, Full Paper)</td></tr>
<tr><td>64</td><td>Zhonghao Sheng, Kaitao Song, Xu Tan, Yi Ren, Wei Ye*, Shikun Zhang and Tao Qin. Automatic Song Writing with Pre-training and Alignment Constraint. In AAAI'21 (CCF Rank A, Full Paper)</td></tr>
<tr><td>65</td><td>Shikun Zhang, Rui Xie, Wei Ye*, Long Chen. Keyword-Based Code Auto-Summarization. Journal of Computer Research and Development, 2020. (CCF Chinese Rank A)</td></tr>
<tr><td>66</td><td>Haixin Wang, Tianhao Zhang, Muzhi Yu, Jinan Sun, Wei Ye, Chen Wang, Shikun Zhang. Stacking Networks Dynamically for Image Restoration Based on the Plug-and-Play Framework. In ECCV'20. (CCF Rank B, Full Paper)</td></tr>
<tr><td>67</td><td>Bo Li, Wei Ye*, Zhonghao Sheng, Rui Xie, Xiangyu Xi and Shikun Zhang. Graph Enhanced Dual Attention Network for Document-Level Relation Extraction. In COLING'20. (CCF Rank B, Full Paper)</td></tr>
<tr><td>68</td><td>Wei Ye, Rui Xie, Jinglei Zhang, Tianxiang Hu, Xiaoying Wang, Shikun Zhang. Leveraging Code Generation to Improve Code Retrieval and Summarization via Dual Learning. In WWW'20. (CCF Rank A, Full Paper)</td></tr>
<tr><td>69</td><td>Jinglei Zhang, Rui Xie, Wei Ye*, Yuhan Zhang, Shikun Zhang. Exploiting Code Knowledge Graph for Bug Localization via Bi-directional Attention. In ICPC'20. (CCF Rank B, Full Paper)</td></tr>
<tr><td>70</td><td>Tong Zhang, Wei Ye*, Xiangyu Xi, Long Zhang, Shikun Zhang, Wen Zhao. Leveraging Human Prior Knowledge to Learn Sense Representations. in ECAI'20. (CCF B, Full Paper)</td></tr>
<tr><td>71</td><td>Haixin Wang, Xingzhang Ren, Jinan Sun, Wei Ye,  Long Chen, Muzhi Yu, Shikun Zhang. Deep Dynamic Boosted Forest. In ACML'20. (CCF Rank C, Full Paper)</td></tr>
<tr><td>72</td><td>Bo Li, Zhonghao Sheng, Wei Ye*, Jinglei Zhang, Kai Liu and Shikun Zhang. Sliding Hierarchical Recurrent Neural Networks for Sequence Classification. In IJCNN'20. (CCF Rank C, Full Paper)</td></tr>
<tr><td>73</td><td>Peiyang Liu, Wei Ye*, Xiangyu Xi, Tong Wang and Shikun Zhang. Not All Synonyms Are Created Equal: Incorporating Similarity of Synonyms to Enhance Word Embeddings. In IJCNN'20. (CCF Rank C, Full Paper)</td></tr>
<tr><td>74</td><td>Wei Ye, Bo Li, Rui Xie, Zhonghao Sheng, Long Chen and Shikun Zhang. Exploiting Entity BIO Tag Embeddings and Multi-task Learning for Relation Extraction with Imbalanced Data. In ACL'19. (CCF Rank A, Full Paper)</td></tr>
<tr><td>75</td><td>Bo Li, Zehua Cheng, Zhenghua Xu, Wei Ye*, Thomas Lukasiewicz and Shikun Zhang. Long Text Analysis Using Sliced Recurrent Neural Network with Breaking Point Information Enrichment. In ICASSP'19 (CCF Rank B, Full Paper)</td></tr>
<tr><td>76</td><td>Rui Xie, Long Chen, Wei Ye*, Zhiyu Li, Tianxiang Hu, Dongdong Du and Shikun Zhang. DeepLink: A Code Knowledge Graph Based Deep Learning Approach for Issue-Commit Link Recovery. In SANER'19 (CCF Rank B, Full Paper)</td></tr>
<tr><td>77</td><td>Long Chen, Wei Ye* and Shikun Zhang. Capturing Source Code Semantics via Tree-based Convolution over API-enhanced AST. ACM International Conference on Computing Frontiers, 2019 (CCF Rank C, Full Paper)</td></tr>
                        </tbody>
                    </table>
                </div>
                
            </div>
        </div>
    </div>
    <div class="footer">
        <div class="foot-container">
            <div class="links">
                <div class="link"><a href="https://www.pku.edu.cn"><i class="dot"></i>Peking University</a></div>
                <div class="link"><a href="https://se.pku.edu.cn"><i class="dot"></i>PKU SERC</a></div>
                <div class="link"><a href="https://eecs.pku.edu.cn"><i class="dot"></i>PKU EECS</a></div>
                <div class="link"><a href="https://ss.pku.edu.cn"><i class="dot"></i>PKU SSM</a></div>
            </div>
            <div class="title">
                <img class="badge" src="https://se.pku.edu.cn/images/content/2021-01/20210131142256311390.png" />
                <div>
                    <div class="text">
                        <a>The Knowledge Computing Lab</a>
                    </div>
                    <div class="subtext">
                        <a>The National Engineering Research Center for Software Engineering</a>
                    </div>
                </div>
            </div>
            <div class="contact">
                <div class="row">
                    <div class="icon"><img src="https://se.pku.edu.cn/images/content/2021-01/20210131142256311237.png" /></div>
                    <div class="text">No.5 Yiheyuan Road Haidian District, Beijing, P.R.China 100871</div>
                </div>
                <div class="row">
                    <div class="icon"><img src="https://se.pku.edu.cn/images/content/2021-01/20210131142256310192.png" /></div>
                    <div class="text">wye#pku.edu.cn</div>
                </div>
            </div>
        </div>
        <div class="copyright">Copyright © National Engineering Research Center For Software Engineering 2020</div>
    </div>
</body>
<footer>
    <!--[if lt IE 9]>
        　　<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        　　<script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->
    <script src="/docs/2020-05/20200507141008607209.js"></script>
    <script src="/docs/2020-06/20200601131132801493.js"></script>
</footer>

</html>

